{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/sfarrukhm/making_models_small/blob/main/knowledge_distillation.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "-hcHFh1ko5Nj"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "from torchvision import datasets, transforms\n",
        "import torchvision\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Below we are preprocessing data for CIFAR-10. We use an arbitrary batch size of 128.\n",
        "transform = torchvision.transforms.Compose([\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(mean=[0.50,0.5,0.5], std=[0.50,0.5,0.5]),\n",
        "])\n",
        "\n",
        "# Loading the CIFAR-10 dataset:\n",
        "\n",
        "train_dataset =datasets.CIFAR10(root='./data', train=True, download=True, transform=transform)\n",
        "test_dataset =  datasets.CIFAR10(root='./data', train=False, download=True, transform=transform)\n",
        "# train_dataset = torch.utils.data.Subset((datasets.CIFAR10(root='./data', train=True, download=True, transform=transform)),range(10000)) # Changed transforms to transform\n",
        "# test_dataset =  torch.utils.data.Subset(datasets.CIFAR10(root='./data', train=False, download=True, transform=transform),range(2000)) # Changed transforms to transform\n",
        "#Dataloaders\n",
        "train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=64, shuffle=True, num_workers=2)\n",
        "test_loader = torch.utils.data.DataLoader(test_dataset, batch_size=64, shuffle=False, num_workers=2)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aBSIyLp690ON",
        "outputId": "4a241ddb-aa4d-4150-c07e-b4917b2b4b9c"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz to ./data/cifar-10-python.tar.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 170M/170M [00:08<00:00, 20.4MB/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting ./data/cifar-10-python.tar.gz to ./data\n",
            "Files already downloaded and verified\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# construct the teacher model\n",
        "class TeacherModel(nn.Module):\n",
        "    def __init__(self, num_classes=10):\n",
        "        super().__init__()\n",
        "        self.features=nn.Sequential(\n",
        "            nn.Conv2d(3, 128, kernel_size=3,\n",
        "                      padding=1),\n",
        "            nn.ReLU(),\n",
        "            nn.Conv2d(128,64,kernel_size=3,padding=1),\n",
        "            nn.ReLU(),\n",
        "            nn.MaxPool2d(kernel_size=2, stride=2),\n",
        "            nn.Conv2d(64,64, kernel_size=3, padding=1),\n",
        "            nn.ReLU(),\n",
        "            nn.Conv2d(64,32,kernel_size=3,padding=1),\n",
        "            nn.ReLU(),\n",
        "            nn.MaxPool2d(kernel_size=2, stride=2)\n",
        "        )\n",
        "        self.classifier=nn.Sequential(\n",
        "            nn.Linear(2048,512),\n",
        "            nn.ReLU(),\n",
        "            nn.Dropout(0.1),\n",
        "            nn.Linear(512, num_classes)\n",
        "        )\n",
        "    def forward(self,x):\n",
        "        x=self.features(x)\n",
        "        x=torch.flatten(x,1)\n",
        "        x=self.classifier(x)\n",
        "        return x\n",
        "\n",
        "\n",
        "## Student Model (way lighter than the teacher model)\n",
        "class StudentModel(nn.Module):\n",
        "    def __init__(self, num_classes=10):\n",
        "        super().__init__()\n",
        "        self.features=nn.Sequential(\n",
        "            nn.Conv2d(3,10,kernel_size=3, padding=1),\n",
        "            nn.ReLU(),\n",
        "\n",
        "            nn.MaxPool2d(kernel_size=2,stride=2),\n",
        "            nn.Conv2d(10,10,kernel_size=3, padding=1),\n",
        "            nn.ReLU(),\n",
        "            nn.MaxPool2d(kernel_size=2, stride=2),\n",
        "        )\n",
        "        self.classifier=nn.Sequential(\n",
        "            nn.Linear(640,256),\n",
        "            nn.ReLU(),\n",
        "            nn.Dropout(0.1),\n",
        "            nn.Linear(256,num_classes)\n",
        "        )\n",
        "    def forward(self,x):\n",
        "        x=self.features(x)\n",
        "        x=torch.flatten(x,1)\n",
        "        x=self.classifier(x)\n",
        "        return x\n"
      ],
      "metadata": {
        "id": "8NWpoO55q6aA"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# training the teacher and student model before the distiallation with cross entropy\n",
        "# optimizer=torch.optim.Adam(m)\n",
        "device=\"cuda\" if torch.cuda.is_available() else 'cpu'\n",
        "from collections import defaultdict\n",
        "log_dict=defaultdict(list)\n",
        "\n",
        "def train(model, train_loader, num_epochs, learning_rate,device, save_model_path=None):\n",
        "    loss_fn = torch.nn.CrossEntropyLoss()\n",
        "    optimizer=torch.optim.Adam(model.parameters(),lr=learning_rate)\n",
        "\n",
        "    model.to(device)\n",
        "    model.train()\n",
        "    for epoch in range(num_epochs):\n",
        "        running_loss=0\n",
        "        for images, labels in train_loader:\n",
        "            images,labels=images.to(device), labels.to(device)\n",
        "\n",
        "            optimizer.zero_grad()\n",
        "            outputs=model(images)\n",
        "            loss=loss_fn(outputs, labels)\n",
        "            loss.backward()\n",
        "\n",
        "            optimizer.step()\n",
        "            running_loss+=loss.item()\n",
        "\n",
        "        print(f\"Epoch {epoch+1}/{num_epochs}, Loss: {running_loss / len(train_loader)}\")\n",
        "    if save_model_path is not None:\n",
        "        torch.save(model.state_dict(),save_model_path)\n",
        "\n",
        "def test(model, test_loader, device):\n",
        "    model.to(device)\n",
        "    model.eval()\n",
        "\n",
        "    correct_predictions=0\n",
        "    total=0\n",
        "    with torch.no_grad():\n",
        "        for images, labels in test_loader:\n",
        "            images,labels=images.to(device), labels.to(device)\n",
        "            outputs=model(images)\n",
        "\n",
        "            _, predicted = torch.max(outputs, 1)\n",
        "\n",
        "            total+=labels.size(0)\n",
        "            correct_predictions+=(labels==predicted).sum()\n",
        "\n",
        "    accuracy=100*correct_predictions/total\n",
        "    print(f\"Total correct predictions: {correct_predictions}\")\n",
        "    print(f\"Total labels: {total}\")\n",
        "    print(f\"Test Accuracy: {accuracy}\")\n",
        "\n",
        "    return correct_predictions, total, accuracy\n"
      ],
      "metadata": {
        "id": "PYGMOdrq7BUe"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "## Cross-entropy run\n",
        "# teacher traing\n",
        "torch.manual_seed(2342)\n",
        "save_path=\"/content/drive/MyDrive/deep_generative_models/trained_models/knowledge_distillation\"\n",
        "# teacher_model=TeacherModel(num_classes=10).to(device)\n",
        "# train(teacher_model, train_loader,\n",
        "#       10, 0.001,device=device, save_model_path=save_path+\"/cifar_teacher_v1.pt\")\n",
        "# torch.save(teacher_model.state_dict(),save_path+\"/cifar_teacher_v1.pt\")"
      ],
      "metadata": {
        "id": "x0H8-g5fvwbd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# testing the teacher\n",
        "test_teacher = test(teacher_model, test_loader, device)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jUiAMRh46gkO",
        "outputId": "d4c61056-5e7c-4012-dab0-33ce97f65946"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Total correct predictions: 7156\n",
            "Total labels: 10000\n",
            "Test Accuracy: 71.55999755859375\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# student traing but without the support fo teacher\n",
        "torch.manual_seed(2342)\n",
        "save_path=\"/content/drive/MyDrive/deep_generative_models/knowledge_distillation\"\n",
        "student_model=StudentModel(num_classes=10).to(device)\n",
        "train(student_model, train_loader,\n",
        "      10, 0.001,device=device, save_model_path=save_path+\"/cifar_student_wo_teacher_v1.pt\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TW8WrLfj7Gud",
        "outputId": "aad45f91-23be-4203-f00f-fc3a1d2e9933"
      },
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10, Loss: 1.5366986973206405\n",
            "Epoch 2/10, Loss: 1.2394564447500516\n",
            "Epoch 3/10, Loss: 1.1167083738557517\n",
            "Epoch 4/10, Loss: 1.0352113188989938\n",
            "Epoch 5/10, Loss: 0.9662601889094429\n",
            "Epoch 6/10, Loss: 0.9080696434849669\n",
            "Epoch 7/10, Loss: 0.8518675702916997\n",
            "Epoch 8/10, Loss: 0.8079483616535011\n",
            "Epoch 9/10, Loss: 0.7643249590912133\n",
            "Epoch 10/10, Loss: 0.7205251159570406\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "test_teacher = test(student_model, test_loader, device)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CoALDBx8J3eY",
        "outputId": "805f915c-5be5-4d53-d567-b03a90fd718a"
      },
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Total correct predictions: 6766\n",
            "Total labels: 10000\n",
            "Test Accuracy: 67.65999603271484\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Distillation Run"
      ],
      "metadata": {
        "id": "iA3qZ0VJAN1u"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# load the trained teacher model\n",
        "teacher_model=TeacherModel()\n",
        "teacher_state_dict=torch.load(\"/content/drive/MyDrive/deep_generative_models/knowledge_distillation/cifar_teacher_v1.pt\",map_location=device)\n",
        "teacher_model.load_state_dict(teacher_state_dict)\n",
        "teacher_model"
      ],
      "metadata": {
        "id": "p6iy4PjzDXL0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def train_knowledge_distillation(teacher,student, train_loader, num_epochs,\n",
        "                                 learning_rate, temperature, soft_training_loss_weight,\n",
        "                                 ce_loss_weight, device):\n",
        "    teacher.eval()\n",
        "    teacher.to(device)\n",
        "    student.train()\n",
        "    student.to(device)\n",
        "    optimizer = torch.optim.Adam(student.parameters(), lr=learning_rate)\n",
        "\n",
        "    loss_fn=torch.nn.CrossEntropyLoss()\n",
        "\n",
        "    for epoch in range(num_epochs):\n",
        "        running_loss=0\n",
        "        for images, labels in train_loader:\n",
        "            images,labels=images.to(device), labels.to(device)\n",
        "\n",
        "            optimizer.zero_grad()\n",
        "            with torch.no_grad():\n",
        "                teacher_logits=teacher(images)\n",
        "\n",
        "            student_logits=student(images)\n",
        "\n",
        "            soft_targets=torch.softmax(teacher_logits/temperature,\n",
        "                                                dim=-1)\n",
        "            soft_probs=torch.softmax(student_logits/temperature,dim=-1)\n",
        "\n",
        "            # porbability distribution loss\n",
        "            kl_div_loss= torch.sum(soft_targets*(soft_targets.log()-soft_probs.log()))/soft_probs.size(0)*temperature**2  #Kullback-Leibler (KL) divergence between two probabilit distributions modeling the same random variable\n",
        "\n",
        "            # classification loss which is cross-entropy loss\n",
        "            ce_loss=loss_fn(student_logits, labels)\n",
        "\n",
        "            # weighted sum of the two losses\n",
        "            loss=soft_training_loss_weight*kl_div_loss + ce_loss_weight*ce_loss\n",
        "\n",
        "            loss.backward()\n",
        "\n",
        "            optimizer.step()\n",
        "\n",
        "            running_loss+=loss.item()\n",
        "        print(f\"Epoch {epoch+1}/{num_epochs}, Loss: {running_loss / len(train_loader)}\")\n",
        "\n",
        "\n",
        "# starting teaching the student\n",
        "student_model=StudentModel()\n",
        "torch.manual_seed(2342)\n",
        "train_knowledge_distillation(teacher=teacher_model, student=student_model, train_loader=train_loader, num_epochs=10, learning_rate=0.001, temperature=7,\n",
        "                             soft_training_loss_weight=0.1, ce_loss_weight=0.9, device=device)\n",
        "\n",
        "\n",
        "torch.save(student_model.state_dict(),\"/content/drive/MyDrive/deep_generative_models/knowledge_distillation/cifar_student_trained_with_teacher.pt\")\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xZG_M2hzFwZw",
        "outputId": "11a0bfd3-bb09-4167-af6e-c7492fd8d908"
      },
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10, Loss: 3.6267738403261776\n",
            "Epoch 2/10, Loss: 2.92132333599393\n",
            "Epoch 3/10, Loss: 2.6230877584508616\n",
            "Epoch 4/10, Loss: 2.4164173636595003\n",
            "Epoch 5/10, Loss: 2.2566777353396503\n",
            "Epoch 6/10, Loss: 2.102309353668671\n",
            "Epoch 7/10, Loss: 1.9779516960044041\n",
            "Epoch 8/10, Loss: 1.8689032418038838\n",
            "Epoch 9/10, Loss: 1.7709855746735088\n",
            "Epoch 10/10, Loss: 1.687798717747564\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# test student accuracy, temp=5\n",
        "test_student = test(student_model, test_loader, device)"
      ],
      "metadata": {
        "id": "Byp6rnyfCAhm",
        "outputId": "e57bf5fd-e325-4981-d4e0-d741507a0f4a",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Total correct predictions: 6535\n",
            "Total labels: 10000\n",
            "Test Accuracy: 65.3499984741211\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# test student accuracy, temp=7\n",
        "test_student = test(student_model, test_loader, device)"
      ],
      "metadata": {
        "id": "eZPiiIxGA8ap",
        "outputId": "707333ad-e251-41e4-e4a1-7837d0d9f69e",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Total correct predictions: 6749\n",
            "Total labels: 10000\n",
            "Test Accuracy: 67.48999786376953\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# test student accuracy, temp=13\n",
        "test_student = test(student_model, test_loader, device)"
      ],
      "metadata": {
        "id": "J4tJniLR-KbN",
        "outputId": "900d799b-05ff-44c9-b464-d76b8b0e69ba",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Total correct predictions: 6639\n",
            "Total labels: 10000\n",
            "Test Accuracy: 66.38999938964844\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# test student accuracy, temp=10\n",
        "test_student = test(student_model, test_loader, device)"
      ],
      "metadata": {
        "id": "tDFbbOEY9vuJ",
        "outputId": "4c8f1a66-98ac-4c91-976a-2a4365c31dd7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Total correct predictions: 6721\n",
            "Total labels: 10000\n",
            "Test Accuracy: 67.20999908447266\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# test student accuracy\n",
        "test_student = test(student_model, test_loader, device)"
      ],
      "metadata": {
        "id": "xQ3PdXiw8UP5",
        "outputId": "79db11d7-aae5-491b-88a9-bf9499d4bcbf",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Total correct predictions: 6631\n",
            "Total labels: 10000\n",
            "Test Accuracy: 66.30999755859375\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# test student accuracy\n",
        "test_student = test(student_model, test_loader, device)"
      ],
      "metadata": {
        "id": "dBotsqX99lM6",
        "outputId": "2c75f002-afad-434a-f085-092644512949",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Total correct predictions: 6573\n",
            "Total labels: 10000\n",
            "Test Accuracy: 65.72999572753906\n"
          ]
        }
      ]
    }
  ]
}